{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaU5oekPl6l7",
        "outputId": "6a7c486c-afbe-4daa-f11c-9a33511e623e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEHamtp4mxeI"
      },
      "source": [
        "import json\n",
        "from collections import Counter"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SiHsgD5LiTi"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxPySXAynX8U"
      },
      "source": [
        "data = []\n",
        "for line in open('/content/drive/My Drive/data/Electronics_5.json', 'r'):\n",
        "    data.append(json.loads(line))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETj85qx7on5f"
      },
      "source": [
        "reviews = [entry[\"reviewText\"] for entry in data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8UHdUHVjgy9"
      },
      "source": [
        "reviews = reviews[:50000]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEcjkco4LjCE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXWuIlaFxKzA"
      },
      "source": [
        "c = Counter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cac6wlGrxd_e"
      },
      "source": [
        "i = 0\n",
        "for review in reviews:\n",
        "\n",
        "  words = review.split()\n",
        "  for word in words:\n",
        "    c[word.lower()]+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l63RQfTcy-6S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JznAiAhrzYOU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3CyH7cJLjuo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CRZcDV0zAaR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9AfkI0uza4I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xu4BTJofC0D"
      },
      "source": [
        "cleaned_reviews = []\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "x = tokenizer.tokenize('Eighty-seven miles to go, yet.  Onward!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAj4yKpDgevw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-sB0oyOiy-e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh2uKmDvLlA2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh43UVCvj4kI"
      },
      "source": [
        "cleaned_reviews = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T0mN_jdLkd_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lGbPxSRzk2N"
      },
      "source": [
        "for review in reviews:\n",
        "\n",
        "  words = tokenizer.tokenize(review)\n",
        "  new_words = []\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "    if c[word]>=5 and word not in stop_words:\n",
        "      new_words.append(word)\n",
        "  new_review = \" \".join(new_words)\n",
        "  cleaned_reviews.append(new_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_v_iFIcjcYZ"
      },
      "source": [
        "cleaned_reviews[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmbBNJZgbqDL"
      },
      "source": [
        "with open('reviews.txt', 'w') as f:\n",
        "    for item in cleaned_reviews:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjhtP2ZEy3c7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJqyDEV8y3gI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hootta8Ay3j1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVWWsCxVy3m-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdZRdTMCy3qE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sshvESnNy3tX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV7WqXYFy3w1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFxHr2Rhy4B_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qs94gRhy4Ik"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLS40wVZbzpT"
      },
      "source": [
        "with open('/content/drive/My Drive/data/reviews.txt') as file:\n",
        "    cleaned_reviews = file.readlines()\n",
        "    cleaned_reviews = [line.rstrip() for line in cleaned_reviews]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go_wgFZvLl7Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaY8Lgsp1htM",
        "outputId": "1edd679a-84ab-48f5-a4b2-e19e569302a5"
      },
      "source": [
        "len(cleaned_reviews)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1689188"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97RAHk8NOzv5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNpC7vjrU7up"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-8GK64KSxyK"
      },
      "source": [
        "WINDOWS_SIZE = 2\n",
        "EMBEDDING_DIM = 10\n",
        "BATCH_SIZE = 1000\n",
        "NUM_EPOCH = 5\n",
        "class Text2DataSet(Dataset):\n",
        "\n",
        "    def __init__(self, window_size=2):\n",
        "\n",
        "        self.context_target = []\n",
        "        self.vocab = set()\n",
        "        for review in cleaned_reviews:\n",
        "          words_tokenized = review.split()\n",
        "          for word in words_tokenized:\n",
        "            self.vocab.add(word)\n",
        "          for i in range(window_size, len(words_tokenized)-window_size):\n",
        "            self.context_target.append(([words_tokenized[i-(j+1)] for j in range(window_size)] +\\\n",
        "                                 [words_tokenized[i+(j+1)] for j in range(window_size)],\n",
        "                                words_tokenized[i]))\n",
        "\n",
        "        self.word_to_idx = {word_tuple: idx for idx, word_tuple in enumerate(self.vocab)}\n",
        "        self.idx_to_word = list(self.word_to_idx.keys())\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context = torch.tensor([self.word_to_idx[w] for w in self.context_target[idx][0]])\n",
        "        target = torch.tensor([self.word_to_idx[self.context_target[idx][1]]])\n",
        "        return context, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.context_target)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3a3c7QULmp4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O1c4a23P6aa"
      },
      "source": [
        "data = Text2DataSet()\n",
        "class CBOW(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, window_size):\n",
        "        super(CBOW, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        embeds = torch.sum(self.embeddings(inputs), dim=1)\n",
        "        out = self.linear(embeds) # nonlinear + projection\n",
        "        log_probs = F.log_softmax(out, dim=1) # softmax compute log probability\n",
        "\n",
        "        return log_probs\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egcmerlNUtpK"
      },
      "source": [
        "model = CBOW(len(data.vocab), EMBEDDING_DIM, WINDOWS_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFhX2OWrV7Ig"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_function = nn.NLLLoss()\n",
        "data_loader = DataLoader(data, batch_size=BATCH_SIZE)\n",
        "cuda_available = torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN1R6VH0Wqlm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zahkQ4MsV-2I"
      },
      "source": [
        "for epoch in range(NUM_EPOCH):\n",
        "    total_loss = 0\n",
        "    for context, target in tqdm(data_loader):\n",
        "        # context: torch.Size([10, 4])\n",
        "        # target:  torch.Size([10, 1])\n",
        "        if context.size()[0] != BATCH_SIZE:\n",
        "            continue\n",
        "\n",
        "        if cuda_available:\n",
        "            context = context.cuda()\n",
        "            target = target.squeeze(1).cuda()\n",
        "            model = model.cuda()\n",
        "\n",
        "        model.zero_grad()\n",
        "        log_probs = model(context)\n",
        "        loss = loss_function(log_probs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpGQbuaEaOVB"
      },
      "source": [
        "my_words = ['camera','clean','depressed','run','wallet']\n",
        "from numpy.linalg import norm\n",
        "all_vec = [[] for i in my_words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrvsYADtW_nV"
      },
      "source": [
        "for k,my_word in enumerate(my_words):\n",
        "  for j,other_word in enumerate(data.vocab):\n",
        "    vec1 = model.embeddings.weight[data.word_to_idx[my_word]]\n",
        "    vec2 = model.embeddings.weight[data.word_to_idx[other_word]]\n",
        "    dist = norm(vec1.cpu().detach().numpy()-vec2.cpu().detach().numpy())\n",
        "    all_vec[k].append({other_word:dist})\n",
        "for i,item in enumerate(all_vec):\n",
        "  all_vec[i] = sorted(all_vec[i], key=lambda x: list(x.values())[0])\n",
        "final_words = []\n",
        "for i,item in enumerate(all_vec):\n",
        "  print(f\"For {my_words[i]}:\")\n",
        "  for j in all_vec[i][1:11]:\n",
        "    word_key = list(j.keys())[0]\n",
        "    print(word_key)\n",
        "    final_words.append(word_key)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQzKkq5ZLoSL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlMFu3O4y1ny"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0soOa1-_y1q0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOR3Da8by1uA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBCeOp6yy1yT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_2BtsFmy11H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxPcb8hmrPK5"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "def tsne_plot():\n",
        "    \"Creates and TSNE model and plots it\"\n",
        "    labels = []\n",
        "    tokens = []\n",
        "\n",
        "    for word in final_words:\n",
        "        tokens.append(model.embeddings.weight[data.word_to_idx[word]].cpu().detach().numpy())\n",
        "        labels.append(word)\n",
        "    \n",
        "    tsne_model = TSNE(perplexity=15, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
        "    new_values = tsne_model.fit_transform(tokens)\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    for value in new_values:\n",
        "        x.append(value[0])\n",
        "        y.append(value[1])\n",
        "        \n",
        "    plt.figure(figsize=(16, 16)) \n",
        "    for i in range(len(x)):\n",
        "        plt.scatter(x[i],y[i])\n",
        "        plt.annotate(labels[i],\n",
        "                     xy=(x[i], y[i]),\n",
        "                     xytext=(5, 2),\n",
        "                     textcoords='offset points',\n",
        "                     ha='right',\n",
        "                     va='bottom')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPkgHxrPcfLx"
      },
      "source": [
        "len(final_words)\n",
        "tsne_plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}